{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENCV - ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.096] global loadsave.cpp:268 findDecoder imread_('/Users/lua/wild_IA/projet_fil_rouge/food-101/data/food-101/images/churros/45579.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Charger une image\u001b[39;00m\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path_image)\n\u001b[0;32m----> 7\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))  \u001b[38;5;66;03m# Redimensionner pour le modèle\u001b[39;00m\n\u001b[1;32m      8\u001b[0m image \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalisation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path_image = \"/Users/lua/wild_IA/projet_fil_rouge/food-101/data/food-101/images/churros/45579.jpg\"\n",
    "# Charger une image\n",
    "image = cv2.imread(path_image)\n",
    "image = cv2.resize(image, (224, 224))  # Redimensionner pour le modèle\n",
    "image = image / 255.0  # Normalisation\n",
    "image = np.expand_dims(image, axis=0)  # Ajouter une dimension pour le batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger le fichier de classes ImageNet\n",
    "imagenet_classes_url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\" # animaux (trouver celui des aliments)\n",
    "#https://gist.githubusercontent.com/kklemon/3d16a10202b2784a6dfc0c7678f4f582/raw/b4278728b144a0584d4930205a5a9faad06235bc/imagenet_class_labels.txt\n",
    "import requests\n",
    "\n",
    "response = requests.get(imagenet_classes_url)\n",
    "imagenet_classes = response.json()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n"
     ]
    }
   ],
   "source": [
    "print(imagenet_classes[643])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-14 09:23:40.720432: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "model = ResNet50(weights='imagenet')  # Chargement du modèle pré-entraîné\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "Class ID prédit : 111\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(image)\n",
    "class_id = np.argmax(predictions)\n",
    "print(f\"Class ID prédit : {class_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La prédiction pour class_id 111 est : flatworm\n"
     ]
    }
   ],
   "source": [
    "# Vérifier la classe correspondant à class_id = 644\n",
    "predicted_label = imagenet_classes[class_id-1]\n",
    "print(f\"La prédiction pour class_id {class_id} est : {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec EfficientNetB0\n",
    "(ça donne tjrs le même résultat (644 == match)) ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "La prédiction pour class_id 644 est : match\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Charger un modèle préentraîné ou personnalisé\n",
    "model = EfficientNetB0(weights='imagenet', include_top=True)\n",
    "\n",
    "# Prédire\n",
    "predictions = model.predict(image)\n",
    "class_id = np.argmax(predictions)\n",
    "\n",
    "# Vérifier la classe correspondant à class_id = 644\n",
    "predicted_label = imagenet_classes[class_id]\n",
    "print(f\"La prédiction pour class_id {class_id} est : {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644\n"
     ]
    }
   ],
   "source": [
    "print(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs nutritionnelles pour pomme: {'calories': 52, 'protéines': 0.3, 'glucides': 14, 'lipides': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'association avec une base de données nutritionnelle\n",
    "food_database = {\n",
    "    \"pomme\": {\"calories\": 52, \"protéines\": 0.3, \"glucides\": 14, \"lipides\": 0.2},\n",
    "    \"banane\": {\"calories\": 89, \"protéines\": 1.1, \"glucides\": 23, \"lipides\": 0.3}\n",
    "}\n",
    "\n",
    "detected_food = \"pomme\"  # Nom détecté\n",
    "nutrition = food_database.get(detected_food, {})\n",
    "print(f\"Valeurs nutritionnelles pour {detected_food}: {nutrition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Charger un modèle pré-entraîné (par exemple YOLOv8n pour la version nano)\n",
    "model = YOLO('yolov8s.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/lua/wild_IA/projet_fil_rouge/food-101/data/food-101/images/waffles/3138.jpg: 448x640 1 pizza, 1 dining table, 269.4ms\n",
      "Speed: 9.3ms preprocess, 269.4ms inference, 12.5ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "# Charger une image locale\n",
    "results = model('/Users/lua/wild_IA/projet_fil_rouge/food-101/data/food-101/images/waffles/3138.jpg')\n",
    "\n",
    "# Parcourir les résultats et afficher chaque image avec ses annotations\n",
    "for result in results:\n",
    "    result.plot()  # Méthode correcte pour afficher l'image avec les détections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe : tensor([54.]), Score : tensor([0.9324]), Coordonnées : tensor([[ 15.8740,  73.5371, 237.7036, 325.0114]])\n",
      "Classe : tensor([54.]), Score : tensor([0.8543]), Coordonnées : tensor([[186.5239,  63.9664, 495.5538, 383.8908]])\n"
     ]
    }
   ],
   "source": [
    "# Parcourir les détections\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        print(f\"Classe : {box.cls}, Score : {box.conf}, Coordonnées : {box.xyxy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
